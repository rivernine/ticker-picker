{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stocks 정보 최신화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pykrx to mysql\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "from pykrx import stock\n",
    "import time\n",
    "from openpyxl import load_workbook\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "ADDR = '192.168.56.100'\n",
    "PORT = '3306'\n",
    "DB = 'INDEX_DUCK'\n",
    "ID = 'root'\n",
    "PW = 'root'\n",
    "# PW = 'test'\n",
    "\n",
    "start = '20200101'\n",
    "end = '20211025'\n",
    "# end = str(datetime.now().date()).replace('-', '')\n",
    "# period = pd.date_range(start=start, end=end).strftime(\"%Y%m%d\").tolist()\n",
    "markets = ['KOSPI', 'KOSDAQ']\n",
    "\n",
    "# 1. 이관 시 ticker기준 조회\n",
    "for market in markets:\n",
    "  tickers = stock.get_market_ticker_list(market = market)\n",
    "  for ticker in tickers:\n",
    "    try:\n",
    "      df = stock.get_market_ohlcv_by_date(start, end, ticker)\n",
    "      time.sleep(0.5)\n",
    "      df['ticker'] = ticker\n",
    "      df = df.rename(columns={'티커':'ticker', '시가':'open', '고가':'high', '저가':'low', '종가':'close', '거래량':'volume'})    \n",
    "      df.index.names = ['date']\n",
    "      df = df[['ticker', 'open', 'high', 'low', 'close', 'volume']]\n",
    "\n",
    "      db_connection = create_engine('mysql+pymysql://'+ ID +':'+ PW +'@'+ ADDR +':'+ PORT +'/'+ DB, encoding='utf-8')\n",
    "      conn = db_connection.connect()\n",
    "      df.to_sql(name='stocks_price', con=db_connection, if_exists='append', index=True, index_label=\"date\")\n",
    "      conn.close()\n",
    "    except Exception as ex:\n",
    "      print(ex, ticker)\n",
    "      pass\n",
    "\n",
    "# 2. 업데이트 시 date기준 조회\n",
    "# for date in period:\n",
    "#   for market in markets:\n",
    "#     try:\n",
    "#       db_connection = create_engine('mysql+pymysql://'+ ID +':'+ PW +'@'+ ADDR +':'+ PORT +'/'+ DB, encoding='utf-8')\n",
    "#       conn = db_connection.connect()\n",
    "#       df = stock.get_market_ohlcv_by_ticker(date, market=market)\n",
    "#       time.sleep(0.5)\n",
    "#       df['date'] = date\n",
    "#       df = df.reset_index().set_index('date').drop(['거래대금', '등락률'], axis=1).rename(columns={'티커':'ticker', '시가':'open', '고가':'high', '저가':'low', '종가':'close', '거래량':'volume'})\n",
    "#       df.to_sql(name='stocks_price', con=db_connection, if_exists='append', index=True, index_label=\"date\")\n",
    "#       conn.close()\n",
    "#     except Exception as ex:\n",
    "#       print(ex, date)\n",
    "#       pass\n",
    "# \n",
    "# 최신화 후 DELETE FROM stocks_price WHERE volume = 0; 실행\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 볼린저밴드 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jack\\AppData\\Local\\Temp/ipykernel_8144/3470133148.py:43: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  pos = (tmpInfo[5] - lo) / (hi - lo)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ex1 (1366, \"Incorrect double value: 'nan' for column `INDEX_DUCK`.`boll`.`position` at row 1\") 083380 20190318 2019-03-18 083380 5010 5010 5010 5010 0.0 nan\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "ADDR = '192.168.56.100'\n",
    "PORT = '3306'\n",
    "DB = 'INDEX_DUCK'\n",
    "ID = 'root'\n",
    "PW = 'root'\n",
    "# PW = 'test'\n",
    "\n",
    "db = pymysql.connect(host=ADDR, port=int(PORT), user=ID, passwd=PW, db=DB, charset='utf8')\n",
    "cursor = db.cursor()\n",
    "try:\n",
    "  getTickersSql = \"SELECT DISTINCT ticker FROM stocks_price\"\n",
    "  cursor.execute(getTickersSql)\n",
    "  tickers = list(cursor.fetchall())\n",
    "\n",
    "  getPeriodSql = \"SELECT DISTINCT date FROM stocks_price ORDER BY date DESC\"\n",
    "  cursor.execute(getPeriodSql)\n",
    "  period = list(cursor.fetchall())\n",
    "\n",
    "  for ticker in tickers:\n",
    "    for date in period:\n",
    "      # print(ticker[0], date[0].strftime(\"%Y%m%d\"))\n",
    "      try:\n",
    "        getLast20InfoSql = \"SELECT * FROM stocks_price WHERE ticker = '\" + ticker[0] + \"' AND date <= '\" + date[0].strftime(\"%Y%m%d\") + \"' ORDER BY date DESC limit 20\"\n",
    "        cursor.execute(getLast20InfoSql)\n",
    "        last20InfoDf = pd.DataFrame(cursor.fetchall())\n",
    "        if len(last20InfoDf.index) < 20:\n",
    "          continue\n",
    "        if last20InfoDf.iloc[0][6] == 0:\n",
    "          continue\n",
    "        \n",
    "        last20InfoDfClose = last20InfoDf.loc[:, 5]\n",
    "        avg = last20InfoDfClose.mean()\n",
    "        std = last20InfoDfClose.std()\n",
    "        tmpInfo = last20InfoDf.loc[0, [0, 1, 5]]\n",
    "        hi = round(avg + std * 2)\n",
    "        me = round(avg)\n",
    "        lo = round(avg - std * 2)\n",
    "        bw = (hi - lo) / me\n",
    "        pos = (tmpInfo[5] - lo) / (hi - lo)\n",
    "\n",
    "        insertBollSql = \"REPLACE INTO boll(date, ticker, close, low, medium, high, bandWidth, position) VALUES(%s, %s, %s, %s, %s, %s, %s, %s)\" \n",
    "        cursor.execute(insertBollSql, (tmpInfo[0], tmpInfo[1], tmpInfo[5], lo, me, hi, bw, pos))\n",
    "        db.commit()\n",
    "      except Exception as ex1:\n",
    "        print('ex1', ex1, ticker[0], date[0].strftime(\"%Y%m%d\"), tmpInfo[0], tmpInfo[1], tmpInfo[5], lo, me, hi, bw, pos)\n",
    "        # print(tmpInfo[0], tmpInfo[1], tmpInfo[2], hi, me, lo, bw)\n",
    "        pass\n",
    "except Exception as ex2:\n",
    "  print('ex2', ex2)\n",
    "  pass\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancing bollinger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception during reset or similar\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jack\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pymysql\\connections.py\", line 756, in _write_bytes\n",
      "    self._sock.sendall(data)\n",
      "ConnectionResetError: [WinError 10054] 현재 연결은 원격 호스트에 의해 강제로 끊겼습니다\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jack\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 682, in _finalize_fairy\n",
      "    fairy._reset(pool)\n",
      "  File \"C:\\Users\\Jack\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sqlalchemy\\pool\\base.py\", line 887, in _reset\n",
      "    pool._dialect.do_rollback(self)\n",
      "  File \"C:\\Users\\Jack\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sqlalchemy\\engine\\default.py\", line 667, in do_rollback\n",
      "    dbapi_connection.rollback()\n",
      "  File \"C:\\Users\\Jack\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pymysql\\connections.py\", line 479, in rollback\n",
      "    self._execute_command(COMMAND.COM_QUERY, \"ROLLBACK\")\n",
      "  File \"C:\\Users\\Jack\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pymysql\\connections.py\", line 814, in _execute_command\n",
      "    self._write_bytes(packet)\n",
      "  File \"C:\\Users\\Jack\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pymysql\\connections.py\", line 759, in _write_bytes\n",
      "    raise err.OperationalError(\n",
      "pymysql.err.OperationalError: (2006, \"MySQL server has gone away (ConnectionResetError(10054, '현재 연결은 원격 호스트에 의해 강제로 끊겼습니다', None, 10054, None))\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ex1 (pymysql.err.IntegrityError) (1062, \"Duplicate entry '000020-2021-10-25-20' for key 'PRIMARY'\")\n",
      "[SQL: INSERT INTO boll (date, ticker, close, period, low, medium, high, `bandWidth`, position) VALUES (%(date)s, %(ticker)s, %(close)s, %(period)s, %(low)s, %(medium)s, %(high)s, %(bandWidth)s, %(position)s)]\n",
      "[parameters: ({'date': datetime.date(2021, 10, 25), 'ticker': '000020', 'close': 16150, 'period': 20, 'low': 15714, 'medium': 17915, 'high': 20116, 'bandWidth': 0.24571588054702764, 'position': 0.09904588823262153}, {'date': datetime.date(2021, 10, 22), 'ticker': '000020', 'close': 16650, 'period': 20, 'low': 15957, 'medium': 17998, 'high': 20038, 'bandWidth': 0.22674741637959772, 'position': 0.16981132075471697}, {'date': datetime.date(2021, 10, 21), 'ticker': '000020', 'close': 16350, 'period': 20, 'low': 15555, 'medium': 17918, 'high': 20280, 'bandWidth': 0.2637013059493247, 'position': 0.16825396825396827}, {'date': datetime.date(2021, 10, 20), 'ticker': '000020', 'close': 17400, 'period': 20, 'low': 15329, 'medium': 17868, 'high': 20406, 'bandWidth': 0.28413924334004925, 'position': 0.40791806184754775}, {'date': datetime.date(2021, 10, 19), 'ticker': '000020', 'close': 17250, 'period': 20, 'low': 14932, 'medium': 17752, 'high': 20573, 'bandWidth': 0.3177670121676431, 'position': 0.41092004963658924}, {'date': datetime.date(2021, 10, 18), 'ticker': '000020', 'close': 17800, 'period': 20, 'low': 14601, 'medium': 17648, 'high': 20694, 'bandWidth': 0.34525158658204896, 'position': 0.5250287214836697}, {'date': datetime.date(2021, 10, 15), 'ticker': '000020', 'close': 18150, 'period': 20, 'low': 14198, 'medium': 17498, 'high': 20797, 'bandWidth': 0.37712881472168247, 'position': 0.59887861797242}, {'date': datetime.date(2021, 10, 14), 'ticker': '000020', 'close': 19000, 'period': 20, 'low': 13903, 'medium': 17348, 'high': 20792, 'bandWidth': 0.3971062946737376, 'position': 0.7398751633038176}  ... displaying 10 of 694 total bound parameter sets ...  {'date': datetime.date(2019, 1, 3), 'ticker': '000020', 'close': 9170, 'period': 20, 'low': 0, 'medium': 0, 'high': 0, 'bandWidth': 0.0, 'position': 0.0}, {'date': datetime.date(2019, 1, 2), 'ticker': '000020', 'close': 9340, 'period': 20, 'low': 0, 'medium': 0, 'high': 0, 'bandWidth': 0.0, 'position': 0.0})]\n",
      "(Background on this error at: https://sqlalche.me/e/14/gkpj)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jack\\AppData\\Local\\Temp/ipykernel_18640/2687744687.py:52: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  pos = (priceDf.iloc[idx]['close'] - lo) / (hi - lo)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "ADDR = '192.168.56.100'\n",
    "PORT = '3306'\n",
    "DB = 'INDEX_DUCK'\n",
    "ID = 'root'\n",
    "PW = 'root'\n",
    "# PW = 'test'\n",
    "db = pymysql.connect(host=ADDR, port=int(PORT), user=ID, passwd=PW, db=DB, charset='utf8')\n",
    "cursor = db.cursor()\n",
    "\n",
    "n_days = [20]\n",
    "\n",
    "start = '20190101'\n",
    "end = '20211025'\n",
    "\n",
    "try:\n",
    "  getTickersSql = \"SELECT DISTINCT ticker FROM stocks_price\"\n",
    "  cursor.execute(getTickersSql)\n",
    "  tickers = list(cursor.fetchall())\n",
    "\n",
    "  for ticker in tickers:\n",
    "    for day in n_days:\n",
    "      try:\n",
    "        # Get ticker's price\n",
    "        cursor.execute(\"SELECT * FROM stocks_price WHERE ticker = '\" + ticker[0] + \"' AND date >= '\"+ start +\"' AND date <= '\"+ end + \"' ORDER BY date DESC\")\n",
    "        priceDf = pd.DataFrame(cursor.fetchall())\n",
    "        priceDf = priceDf.rename(columns={0: 'date', 1:'ticker', 2:'open', 3:'high', 4:'low', 5:'close', 6:'volume'}).drop(['open', 'high', 'low', 'volume'], axis=1)\n",
    "        # \n",
    "        # 실행 전 Alter table로 period 컬럼 추가할 것!!\n",
    "        # \n",
    "        priceDf['period'] = day\n",
    "        priceDf['low'] = 0\n",
    "        priceDf['medium'] = 0\n",
    "        priceDf['high'] = 0\n",
    "        priceDf['bandWidth'] = 0.0\n",
    "        priceDf['position'] = 0.0\n",
    "        # Set bandWidth, Bollinger\n",
    "        for idx in range(0, len(priceDf)):\n",
    "          if idx + day > len(priceDf) - 1:\n",
    "            continue\n",
    "          copyDf = priceDf[idx:idx+day].loc[:, 'close'].copy()\n",
    "          avg = copyDf.mean()\n",
    "          std = copyDf.std()\n",
    "          \n",
    "          lo = round(avg - std * 2)\n",
    "          me = round(avg)\n",
    "          hi = round(avg + std * 2)\n",
    "          bw = (hi - lo) / me\n",
    "          pos = (priceDf.iloc[idx]['close'] - lo) / (hi - lo)\n",
    "          priceDf.at[idx, 'low'] = lo\n",
    "          priceDf.at[idx, 'medium'] = me\n",
    "          priceDf.at[idx, 'high'] = hi\n",
    "          priceDf.at[idx, 'bandWidth'] = bw\n",
    "          priceDf.at[idx, 'position'] = pos\n",
    "\n",
    "        bollDf = priceDf.reset_index().set_index('date').drop(['index'], axis=1)\n",
    "        \n",
    "        db_connection = create_engine('mysql+pymysql://'+ ID +':'+ PW +'@'+ ADDR +':'+ PORT +'/'+ DB, encoding='utf-8')\n",
    "        conn = db_connection.connect()\n",
    "        bollDf.to_sql(name='boll', con=db_connection, if_exists='append', index=True, index_label=\"date\")        \n",
    "        conn.close()\n",
    "      except Exception as ex1:\n",
    "        print('ex1', ex1)\n",
    "        pass\n",
    "except Exception as ex2:\n",
    "  print('ex2', ex2)\n",
    "  pass\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z-SCORE\n",
    "- (현재값 - 평균) / 표준편차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "import datetime\n",
    "\n",
    "ADDR = '192.168.56.100'\n",
    "PORT = '3306'\n",
    "DB = 'INDEX_DUCK'\n",
    "ID = 'root'\n",
    "# PW = 'root'\n",
    "PW = 'test'\n",
    "\n",
    "db = pymysql.connect(host=ADDR, port=int(PORT), user=ID, passwd=PW, db=DB, charset='utf8')\n",
    "cursor = db.cursor()\n",
    "\n",
    "# n_days = [10, 20, 30, 90, 180]\n",
    "n_days = [180]\n",
    "\n",
    "try:\n",
    "  getTickersSql = \"SELECT DISTINCT ticker FROM stocks_price\"\n",
    "  cursor.execute(getTickersSql)\n",
    "  tickers = list(cursor.fetchall())\n",
    "\n",
    "  getPeriodSql = \"SELECT DISTINCT date FROM stocks_price ORDER BY date DESC\"\n",
    "  cursor.execute(getPeriodSql)\n",
    "  period = list(cursor.fetchall())\n",
    "\n",
    "  for ticker in tickers:\n",
    "    for date in period:\n",
    "      for day in n_days:\n",
    "        # print(ticker[0], date[0].strftime(\"%Y%m%d\"))\n",
    "        try:\n",
    "          getLastNBollSql = \"SELECT * FROM boll WHERE ticker = '\" + ticker[0] + \"' AND date <= '\" + date[0].strftime(\"%Y%m%d\") + \"' ORDER BY date DESC limit \" + str(day)\n",
    "          cursor.execute(getLastNBollSql)\n",
    "          lastNBollDf = pd.DataFrame(cursor.fetchall())\n",
    "          if len(lastNBollDf.index) < day:\n",
    "            continue\n",
    "\n",
    "          lastNBollBandWidthDf = lastNBollDf.loc[:, 6]\n",
    "          avg = lastNBollBandWidthDf.mean()\n",
    "          std = lastNBollBandWidthDf.std()\n",
    "          tmpInfo = lastNBollDf.loc[0, [0, 1, 6]]\n",
    "          z_score = (tmpInfo[6] - avg) / std\n",
    "          \n",
    "          insertZScoreSql = \"REPLACE INTO z_score(date, ticker, period, bandWidth, z_score) VALUES(%s, %s, %s, %s, %s)\"\n",
    "          cursor.execute(insertZScoreSql, (tmpInfo[0], tmpInfo[1], day, tmpInfo[6], z_score))\n",
    "          db.commit()\n",
    "        except Exception as ex1:\n",
    "          print('ex1', ex1, ticker[0], date[0].strftime(\"%Y%m%d\"))\n",
    "          # print(tmpInfo[0], tmpInfo[1], tmpInfo[2], hi, me, lo, bw)\n",
    "          pass\n",
    "except Exception as ex2:\n",
    "  print('ex2', ex2)\n",
    "  pass\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancing Z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "import datetime\n",
    "\n",
    "ADDR = '192.168.56.100'\n",
    "PORT = '3306'\n",
    "DB = 'INDEX_DUCK'\n",
    "ID = 'root'\n",
    "# PW = 'root'\n",
    "PW = 'test'\n",
    "\n",
    "db = pymysql.connect(host=ADDR, port=int(PORT), user=ID, passwd=PW, db=DB, charset='utf8')\n",
    "cursor = db.cursor()\n",
    "\n",
    "# n_days = [10, 20, 30, 90, 180]\n",
    "n_days = [180]\n",
    "\n",
    "start = '20190101'\n",
    "end = '20211025'\n",
    "\n",
    "try:\n",
    "  getTickersSql = \"SELECT DISTINCT ticker FROM stocks_price\"\n",
    "  cursor.execute(getTickersSql)\n",
    "  tickers = list(cursor.fetchall())\n",
    "\n",
    "  for ticker in tickers:\n",
    "    for day in n_days:\n",
    "      try:\n",
    "        # Get ticker's bollinger\n",
    "        cursor.execute(\"SELECT * FROM boll WHERE ticker = '\" + ticker[0] + \" AND date >= '\"+ start +\"' AND date <= '\"+ end + \"' ORDER BY date DESC\")\n",
    "        bollDf = pd.DataFrame(cursor.fetchall())\n",
    "        bollDf = bollDf.rename(columns={0: 'date', 1:'ticker', 2:'close', 3:'low', 4:'medium', 5:'high', 6:'bandWidth', 7:'position'})\n",
    "        bollDf['period'] = day\n",
    "        bollDf['z_score'] = 0\n",
    "        # Set z_score\n",
    "        for idx in range(0, len(bollDf)):\n",
    "          if idx + day > len(bollDf) - 1:\n",
    "            continue\n",
    "          copyDf = bollDf[idx:idx+day].loc[:, 'bandWidth'].copy()\n",
    "          avg = copyDf.mean()\n",
    "          std = copyDf.std()\n",
    "          bollDf.at[idx, 'z_score'] = (bollDf.iloc[idx]['bandWidth'] - avg) / std\n",
    "        bollDf = bollDf.reset_index().set_index('date').drop(['index', 'close', 'low', 'medium', 'high', 'posision'], axis=1)\n",
    "        # db_connection = create_engine('mysql+pymysql://'+ ID +':'+ PW +'@'+ ADDR +':'+ PORT +'/'+ DB, encoding='utf-8')\n",
    "        # conn = db_connection.connect()\n",
    "        # bollDf.to_sql(name='z_score', con=db_connection, if_exists='append', index=True, index_label=\"date\")        \n",
    "        # conn.close()\n",
    "      except Exception as ex1:\n",
    "        print('ex1', ex1, ticker[0])\n",
    "        pass\n",
    "except Exception as ex2:\n",
    "  print('ex2', ex2)\n",
    "  pass\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFI\n",
    "- TP(Typical price) = (당일 고가 + 당일 저가 + 당일 종가) / 3\n",
    "- RMF = TP * 당일 거래량\n",
    "  - Positive RMF: 당일 TP > 전일 TP\n",
    "  - Negative RMF: 당일 TP < 전일 TP\n",
    "- MFI = n일간 positive RMF 합계 / (n일간 positive RMF 합계 + n일간 negative RMF 합계) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "import datetime\n",
    "\n",
    "ADDR = '192.168.56.100'\n",
    "PORT = '3306'\n",
    "DB = 'INDEX_DUCK'\n",
    "ID = 'root'\n",
    "PW = 'root'\n",
    "# PW = 'test'\n",
    "\n",
    "db = pymysql.connect(host=ADDR, port=int(PORT), user=ID, passwd=PW, db=DB, charset='utf8')\n",
    "cursor = db.cursor()\n",
    "\n",
    "n_days = [10]\n",
    "\n",
    "try:\n",
    "  getTickersSql = \"SELECT DISTINCT ticker FROM stocks_price\"\n",
    "  cursor.execute(getTickersSql)\n",
    "  tickers = list(cursor.fetchall())\n",
    "\n",
    "  getPeriodSql = \"SELECT DISTINCT date FROM stocks_price ORDER BY date DESC\"\n",
    "  cursor.execute(getPeriodSql)\n",
    "  period = list(cursor.fetchall())\n",
    "\n",
    "  for ticker in tickers:\n",
    "    for date in period:\n",
    "      for day in n_days:\n",
    "        # print(ticker[0], date[0].strftime(\"%Y%m%d\"))\n",
    "        try:\n",
    "          getLast10InfoSql = \"SELECT * FROM stocks_price WHERE ticker = '\" + ticker[0] + \"' AND date <= '\" + date[0].strftime(\"%Y%m%d\") + \"' ORDER BY date DESC limit \" + str(day + 1)\n",
    "          cursor.execute(getLast10InfoSql)\n",
    "          last10InfoDf = pd.DataFrame(cursor.fetchall())\n",
    "          if len(last10InfoDf.index) < day + 1:\n",
    "            continue\n",
    "          tpList = []\n",
    "          for idx in last10InfoDf.index:\n",
    "            info = last10InfoDf.loc[idx]\n",
    "            tpList.append(round((info[3] + info[4] + info[5]) / 3))\n",
    "          last10InfoDf['TP'] = tpList\n",
    "\n",
    "          positiveRMF = 0\n",
    "          negativeRMF = 0\n",
    "          for idx in range(0, len(last10InfoDf) - 1):\n",
    "            today = last10InfoDf.iloc[idx]\n",
    "            yesterday = last10InfoDf.iloc[idx + 1]\n",
    "            if today['TP'] > yesterday['TP']:\n",
    "              # positive\n",
    "              positiveRMF += today['TP'] * today[6]\n",
    "            elif today['TP'] < yesterday['TP']:\n",
    "              # negative\n",
    "              negativeRMF += today['TP'] * today[6]\n",
    "          \n",
    "          MFI = positiveRMF / (positiveRMF + negativeRMF) * 100\n",
    "          todayInfo = last10InfoDf.iloc[0, [0, 1, 7]]\n",
    "\n",
    "          insertBollSql = \"REPLACE INTO mfi(date, ticker, period, tp, mfi) VALUES(%s, %s, %s, %s, %s)\"\n",
    "          cursor.execute(insertBollSql, (todayInfo[0], todayInfo[1], day, todayInfo['TP'], MFI))\n",
    "          db.commit()\n",
    "        except Exception as ex1:\n",
    "          print('ex1', ex1, ticker[0], date[0].strftime(\"%Y%m%d\"))\n",
    "          pass\n",
    "except Exception as ex2:\n",
    "  print('ex2', ex2)\n",
    "  pass\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhancing MFI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ex1 division by zero 000040\n",
      "ex1 division by zero 000150\n",
      "ex1 division by zero 000155\n",
      "ex1 division by zero 000157\n",
      "ex1 division by zero 000210\n",
      "ex1 division by zero 000210\n",
      "ex1 division by zero 000215\n",
      "ex1 division by zero 000215\n",
      "ex1 division by zero 001020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jack\\AppData\\Local\\Temp/ipykernel_15928/2546899101.py:54: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "  MFI = round(positiveRMF / (positiveRMF + negativeRMF) * 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ex1 cannot convert float NaN to integer 001020\n",
      "ex1 division by zero 001210\n",
      "ex1 division by zero 001770\n",
      "ex1 division by zero 001770\n",
      "ex1 division by zero 002070\n",
      "ex1 division by zero 002380\n",
      "ex1 division by zero 002380\n",
      "ex1 division by zero 002420\n",
      "ex1 division by zero 002420\n",
      "ex1 division by zero 002630\n",
      "ex1 division by zero 002840\n",
      "ex1 division by zero 003280\n",
      "ex1 division by zero 003280\n",
      "ex1 division by zero 003410\n",
      "ex1 division by zero 003410\n",
      "ex1 division by zero 003550\n",
      "ex1 division by zero 003550\n",
      "ex1 division by zero 003555\n",
      "ex1 division by zero 003555\n",
      "ex1 division by zero 003620\n",
      "ex1 division by zero 003620\n",
      "ex1 division by zero 004150\n",
      "ex1 cannot convert float NaN to integer 004150\n",
      "ex1 division by zero 004540\n",
      "ex1 division by zero 004540\n",
      "ex1 division by zero 004545\n",
      "ex1 division by zero 004545\n",
      "ex1 division by zero 004920\n",
      "ex1 cannot convert float NaN to integer 004920\n",
      "ex1 cannot convert float NaN to integer 005420\n",
      "ex1 division by zero 005850\n",
      "ex1 division by zero 005850\n",
      "ex1 division by zero 006580\n",
      "ex1 division by zero 006580\n",
      "ex1 division by zero 006980\n",
      "ex1 division by zero 007120\n",
      "ex1 division by zero 007530\n",
      "ex1 division by zero 007530\n",
      "ex1 division by zero 007630\n",
      "ex1 division by zero 007630\n",
      "ex1 division by zero 007700\n",
      "ex1 cannot convert float NaN to integer 007700\n",
      "ex1 division by zero 008060\n",
      "ex1 cannot convert float NaN to integer 008060\n",
      "ex1 division by zero 00806K\n",
      "ex1 cannot convert float NaN to integer 00806K\n",
      "ex1 division by zero 009410\n",
      "ex1 division by zero 009410\n",
      "ex1 division by zero 009415\n",
      "ex1 division by zero 009415\n",
      "ex1 division by zero 009620\n",
      "ex1 cannot convert float NaN to integer 009620\n",
      "ex1 division by zero 009730\n",
      "ex1 division by zero 009730\n",
      "ex1 division by zero 009810\n",
      "ex1 division by zero 009810\n",
      "ex1 division by zero 010140\n",
      "ex1 division by zero 010145\n",
      "ex1 division by zero 010280\n",
      "ex1 division by zero 010580\n",
      "ex1 division by zero 010580\n",
      "ex1 division by zero 010660\n",
      "ex1 cannot convert float NaN to integer 010660\n",
      "ex1 division by zero 011300\n",
      "ex1 division by zero 011300\n",
      "ex1 division by zero 011690\n",
      "ex1 division by zero 011690\n",
      "ex1 division by zero 011790\n",
      "ex1 division by zero 012170\n",
      "ex1 division by zero 012170\n",
      "ex1 division by zero 012340\n",
      "ex1 division by zero 012600\n",
      "ex1 division by zero 012600\n",
      "ex1 division by zero 013000\n",
      "ex1 division by zero 013000\n",
      "ex1 division by zero 013520\n",
      "ex1 division by zero 013720\n",
      "ex1 division by zero 013720\n",
      "ex1 division by zero 014100\n",
      "ex1 division by zero 014100\n",
      "ex1 division by zero 015230\n",
      "ex1 division by zero 015260\n",
      "ex1 division by zero 015540\n",
      "ex1 division by zero 015540\n",
      "ex1 division by zero 016250\n",
      "ex1 division by zero 016250\n",
      "ex1 division by zero 016380\n",
      "ex1 cannot convert float NaN to integer 016380\n",
      "ex1 division by zero 016385\n",
      "ex1 division by zero 016670\n",
      "ex1 division by zero 016670\n",
      "ex1 division by zero 017650\n",
      "ex1 division by zero 017650\n",
      "ex1 division by zero 018120\n",
      "ex1 cannot convert float NaN to integer 019010\n",
      "ex1 division by zero 019590\n",
      "ex1 division by zero 019590\n",
      "ex1 division by zero 020560\n",
      "ex1 division by zero 020560\n",
      "ex1 division by zero 021820\n",
      "ex1 division by zero 021820\n",
      "ex1 division by zero 023450\n",
      "ex1 division by zero 024810\n",
      "ex1 cannot convert float NaN to integer 024810\n",
      "ex1 division by zero 024830\n",
      "ex1 division by zero 024830\n",
      "ex1 division by zero 025320\n",
      "ex1 division by zero 025320\n",
      "ex1 division by zero 025560\n",
      "ex1 cannot convert float NaN to integer 025560\n",
      "ex1 division by zero 029480\n",
      "ex1 division by zero 030790\n",
      "ex1 division by zero 031980\n",
      "ex1 division by zero 031980\n",
      "ex1 division by zero 032350\n",
      "ex1 division by zero 032790\n",
      "ex1 division by zero 032790\n",
      "ex1 division by zero 032860\n",
      "ex1 division by zero 032860\n",
      "ex1 division by zero 033340\n",
      "ex1 division by zero 033340\n",
      "ex1 division by zero 033540\n",
      "ex1 cannot convert float NaN to integer 033540\n",
      "ex1 division by zero 033790\n",
      "ex1 division by zero 033790\n",
      "ex1 division by zero 035290\n",
      "ex1 division by zero 035290\n",
      "ex1 division by zero 035810\n",
      "ex1 division by zero 035810\n",
      "ex1 division by zero 036180\n",
      "ex1 division by zero 036180\n",
      "ex1 division by zero 036420\n",
      "ex1 division by zero 036830\n",
      "ex1 division by zero 036830\n",
      "ex1 division by zero 038340\n",
      "ex1 division by zero 038340\n",
      "ex1 division by zero 039310\n",
      "ex1 division by zero 039310\n",
      "ex1 division by zero 039670\n",
      "ex1 division by zero 039670\n",
      "ex1 division by zero 042670\n",
      "ex1 division by zero 042670\n",
      "ex1 division by zero 043100\n",
      "ex1 division by zero 043100\n",
      "ex1 division by zero 043590\n",
      "ex1 division by zero 043590\n",
      "ex1 division by zero 043650\n",
      "ex1 division by zero 043650\n",
      "ex1 division by zero 044180\n",
      "ex1 division by zero 044180\n",
      "ex1 division by zero 044380\n",
      "ex1 division by zero 044380\n",
      "ex1 division by zero 044490\n",
      "ex1 division by zero 044490\n",
      "ex1 division by zero 045890\n",
      "ex1 division by zero 045890\n",
      "ex1 division by zero 046070\n",
      "ex1 division by zero 046070\n",
      "ex1 division by zero 046970\n",
      "ex1 division by zero 046970\n",
      "ex1 division by zero 049180\n",
      "ex1 division by zero 049180\n",
      "ex1 division by zero 049470\n",
      "ex1 division by zero 049470\n",
      "ex1 division by zero 050120\n",
      "ex1 division by zero 050320\n",
      "ex1 division by zero 050320\n",
      "ex1 division by zero 050540\n",
      "ex1 division by zero 050540\n",
      "ex1 division by zero 052190\n",
      "ex1 division by zero 052190\n",
      "ex1 division by zero 052300\n",
      "ex1 division by zero 052300\n",
      "ex1 division by zero 052400\n",
      "ex1 division by zero 052400\n",
      "ex1 division by zero 052770\n",
      "ex1 division by zero 052770\n",
      "ex1 division by zero 053060\n",
      "ex1 cannot convert float NaN to integer 053060\n",
      "ex1 division by zero 053110\n",
      "ex1 division by zero 053110\n",
      "ex1 division by zero 053450\n",
      "ex1 division by zero 053450\n",
      "ex1 division by zero 053660\n",
      "ex1 division by zero 053660\n",
      "ex1 division by zero 053950\n",
      "ex1 division by zero 053950\n",
      "ex1 division by zero 054220\n",
      "ex1 division by zero 054220\n",
      "ex1 division by zero 054780\n",
      "ex1 division by zero 056000\n",
      "ex1 division by zero 056000\n",
      "ex1 division by zero 056730\n",
      "ex1 division by zero 056730\n",
      "ex1 division by zero 058220\n",
      "ex1 division by zero 058220\n",
      "ex1 division by zero 058420\n",
      "ex1 division by zero 058420\n",
      "ex1 division by zero 058450\n",
      "ex1 division by zero 058450\n",
      "ex1 division by zero 058530\n",
      "ex1 division by zero 058530\n",
      "ex1 division by zero 060300\n",
      "ex1 division by zero 060300\n",
      "ex1 division by zero 064090\n",
      "ex1 division by zero 064090\n",
      "ex1 division by zero 064510\n",
      "ex1 division by zero 064510\n",
      "ex1 division by zero 064520\n",
      "ex1 division by zero 064520\n",
      "ex1 division by zero 065150\n",
      "ex1 division by zero 065150\n",
      "ex1 division by zero 065420\n",
      "ex1 division by zero 065420\n",
      "ex1 division by zero 065560\n",
      "ex1 division by zero 065560\n",
      "ex1 division by zero 065570\n",
      "ex1 division by zero 065570\n",
      "ex1 division by zero 066110\n",
      "ex1 division by zero 066110\n",
      "ex1 division by zero 066790\n",
      "ex1 division by zero 066790\n",
      "ex1 division by zero 066980\n",
      "ex1 division by zero 066980\n",
      "ex1 division by zero 069110\n",
      "ex1 division by zero 069110\n",
      "ex1 division by zero 069330\n",
      "ex1 division by zero 069330\n",
      "ex1 division by zero 069460\n",
      "ex1 division by zero 069460\n",
      "ex1 division by zero 069540\n",
      "ex1 division by zero 069540\n",
      "ex1 division by zero 070300\n",
      "ex1 division by zero 070300\n",
      "ex1 division by zero 071460\n",
      "ex1 division by zero 071460\n",
      "ex1 division by zero 073010\n",
      "ex1 division by zero 073010\n",
      "ex1 division by zero 073570\n",
      "ex1 division by zero 073570\n",
      "ex1 division by zero 078590\n",
      "ex1 division by zero 078590\n",
      "ex1 division by zero 078940\n",
      "ex1 division by zero 078940\n",
      "ex1 division by zero 079190\n",
      "ex1 division by zero 079190\n",
      "ex1 division by zero 080530\n",
      "ex1 division by zero 080530\n",
      "ex1 division by zero 082660\n",
      "ex1 division by zero 082660\n",
      "ex1 division by zero 083470\n",
      "ex1 division by zero 083470\n",
      "ex1 division by zero 083640\n",
      "ex1 division by zero 083640\n",
      "ex1 division by zero 083660\n",
      "ex1 division by zero 083660\n",
      "ex1 division by zero 084180\n",
      "ex1 division by zero 084180\n",
      "ex1 division by zero 086450\n",
      "ex1 division by zero 086520\n",
      "ex1 division by zero 086520\n",
      "ex1 division by zero 089530\n",
      "ex1 division by zero 089530\n",
      "ex1 cannot convert float NaN to integer 089590\n",
      "ex1 division by zero 090740\n",
      "ex1 division by zero 090740\n",
      "ex1 division by zero 091970\n",
      "ex1 cannot convert float NaN to integer 091970\n",
      "ex1 division by zero 095720\n",
      "ex1 division by zero 096690\n",
      "ex1 division by zero 096690\n",
      "ex1 division by zero 097230\n",
      "ex1 division by zero 097230\n",
      "ex1 division by zero 099410\n",
      "ex1 division by zero 099410\n",
      "ex1 division by zero 099520\n",
      "ex1 division by zero 099520\n",
      "ex1 division by zero 101000\n",
      "ex1 division by zero 101000\n",
      "ex1 division by zero 101400\n",
      "ex1 division by zero 101680\n",
      "ex1 division by zero 101680\n",
      "ex1 division by zero 103230\n",
      "ex1 division by zero 103230\n",
      "ex1 division by zero 104540\n",
      "ex1 division by zero 104540\n",
      "ex1 division by zero 106080\n",
      "ex1 division by zero 106080\n",
      "ex1 division by zero 106520\n",
      "ex1 division by zero 106520\n",
      "ex1 division by zero 108230\n",
      "ex1 division by zero 108860\n",
      "ex1 division by zero 108860\n",
      "ex1 division by zero 109070\n",
      "ex1 division by zero 109070\n",
      "ex1 division by zero 114120\n",
      "ex1 division by zero 114190\n",
      "ex1 division by zero 114190\n",
      "ex1 division by zero 114570\n",
      "ex1 division by zero 114570\n",
      "ex1 division by zero 114810\n",
      "ex1 division by zero 114810\n",
      "ex1 division by zero 115180\n",
      "ex1 division by zero 115180\n",
      "ex1 division by zero 115530\n",
      "ex1 division by zero 115530\n",
      "ex1 division by zero 121890\n",
      "ex1 division by zero 121890\n",
      "ex1 division by zero 123010\n",
      "ex1 division by zero 123750\n",
      "ex1 division by zero 123750\n",
      "ex1 division by zero 126870\n",
      "ex1 division by zero 126870\n",
      "ex1 division by zero 127160\n",
      "ex1 division by zero 127160\n",
      "ex1 division by zero 130660\n",
      "ex1 cannot convert float NaN to integer 130660\n",
      "ex1 division by zero 131090\n",
      "ex1 division by zero 131090\n",
      "ex1 division by zero 131100\n",
      "ex1 division by zero 138360\n",
      "ex1 division by zero 138360\n",
      "ex1 division by zero 141020\n",
      "ex1 division by zero 141020\n",
      "ex1 division by zero 144620\n",
      "ex1 division by zero 144620\n",
      "ex1 division by zero 144960\n",
      "ex1 division by zero 145210\n",
      "ex1 division by zero 145210\n",
      "ex1 division by zero 153460\n",
      "ex1 division by zero 153460\n",
      "ex1 cannot convert float NaN to integer 156100\n",
      "ex1 cannot convert float NaN to integer 156100\n",
      "ex1 division by zero 158310\n",
      "ex1 division by zero 158310\n",
      "ex1 division by zero 159910\n",
      "ex1 division by zero 159910\n",
      "ex1 division by zero 160600\n",
      "ex1 division by zero 160600\n",
      "ex1 division by zero 168330\n",
      "ex1 division by zero 168330\n",
      "ex1 division by zero 174880\n",
      "ex1 division by zero 176440\n",
      "ex1 division by zero 176440\n",
      "ex1 division by zero 178780\n",
      "ex1 division by zero 178780\n",
      "ex1 division by zero 180400\n",
      "ex1 division by zero 180400\n",
      "ex1 division by zero 182360\n",
      "ex1 cannot convert float NaN to integer 182360\n",
      "ex1 division by zero 182690\n",
      "ex1 division by zero 182690\n",
      "ex1 division by zero 189330\n",
      "ex1 division by zero 189980\n",
      "ex1 division by zero 192410\n",
      "ex1 division by zero 192410\n",
      "ex1 division by zero 196450\n",
      "ex1 division by zero 196450\n",
      "ex1 division by zero 196490\n",
      "ex1 cannot convert float NaN to integer 196490\n",
      "ex1 division by zero 206400\n",
      "ex1 division by zero 208350\n",
      "ex1 division by zero 208350\n",
      "ex1 division by zero 208860\n",
      "ex1 division by zero 208860\n",
      "ex1 cannot convert float NaN to integer 214270\n",
      "ex1 division by zero 214310\n",
      "ex1 division by zero 214370\n",
      "ex1 division by zero 214370\n",
      "ex1 division by zero 215090\n",
      "ex1 division by zero 215090\n",
      "ex1 division by zero 215380\n",
      "ex1 division by zero 215600\n",
      "ex1 division by zero 215600\n",
      "ex1 division by zero 219550\n",
      "ex1 division by zero 219550\n",
      "ex1 division by zero 221610\n",
      "ex1 division by zero 221610\n",
      "ex1 division by zero 222810\n",
      "ex1 cannot convert float NaN to integer 222810\n",
      "ex1 division by zero 223310\n",
      "ex1 division by zero 223310\n",
      "ex1 division by zero 225220\n",
      "ex1 division by zero 225330\n",
      "ex1 cannot convert float NaN to integer 225330\n",
      "ex1 division by zero 230240\n",
      "ex1 division by zero 230980\n",
      "ex1 division by zero 230980\n",
      "ex1 division by zero 238090\n",
      "ex1 cannot convert float NaN to integer 238090\n",
      "ex1 division by zero 239340\n",
      "ex1 division by zero 239340\n",
      "ex1 cannot convert float NaN to integer 239890\n",
      "ex1 cannot convert float NaN to integer 239890\n",
      "ex1 division by zero 250930\n",
      "ex1 division by zero 250930\n",
      "ex1 division by zero 254120\n",
      "ex1 division by zero 254120\n",
      "ex1 division by zero 256630\n",
      "ex1 division by zero 256630\n",
      "ex1 division by zero 256840\n",
      "ex1 division by zero 256840\n",
      "ex1 division by zero 257370\n",
      "ex1 division by zero 257370\n",
      "ex1 division by zero 258790\n",
      "ex1 division by zero 258790\n",
      "ex1 cannot convert float NaN to integer 258830\n",
      "ex1 division by zero 260970\n",
      "ex1 cannot convert float NaN to integer 260970\n",
      "ex1 division by zero 261200\n",
      "ex1 cannot convert float NaN to integer 261200\n",
      "ex1 division by zero 263540\n",
      "ex1 division by zero 263540\n",
      "ex1 division by zero 263920\n",
      "ex1 division by zero 263920\n",
      "ex1 division by zero 264850\n",
      "ex1 division by zero 264850\n",
      "ex1 division by zero 267320\n",
      "ex1 division by zero 267320\n",
      "ex1 division by zero 267850\n",
      "ex1 division by zero 267850\n",
      "ex1 division by zero 270520\n",
      "ex1 division by zero 270520\n",
      "ex1 division by zero 273060\n",
      "ex1 division by zero 273060\n",
      "ex1 division by zero 277880\n",
      "ex1 division by zero 277880\n",
      "ex1 division by zero 281740\n",
      "ex1 division by zero 281740\n",
      "ex1 division by zero 284620\n",
      "ex1 division by zero 284620\n",
      "ex1 division by zero 287410\n",
      "ex1 division by zero 287410\n",
      "ex1 division by zero 291230\n",
      "ex1 division by zero 291230\n",
      "ex1 division by zero 297570\n",
      "ex1 division by zero 297570\n",
      "ex1 division by zero 298690\n",
      "ex1 division by zero 298690\n",
      "ex1 division by zero 299170\n",
      "ex1 division by zero 299170\n",
      "ex1 division by zero 303030\n",
      "ex1 division by zero 303030\n",
      "ex1 division by zero 306620\n",
      "ex1 division by zero 306620\n",
      "ex1 division by zero 307180\n",
      "ex1 division by zero 307180\n",
      "ex1 division by zero 307280\n",
      "ex1 division by zero 307280\n",
      "ex1 division by zero 307750\n",
      "ex1 division by zero 307750\n",
      "ex1 division by zero 307870\n",
      "ex1 division by zero 307870\n",
      "ex1 division by zero 309930\n",
      "ex1 division by zero 309930\n",
      "ex1 division by zero 310200\n",
      "ex1 division by zero 310200\n",
      "ex1 division by zero 310870\n",
      "ex1 division by zero 310870\n",
      "ex1 division by zero 313750\n",
      "ex1 division by zero 313750\n",
      "ex1 division by zero 317240\n",
      "ex1 division by zero 317240\n",
      "ex1 division by zero 319400\n",
      "ex1 division by zero 319400\n",
      "ex1 division by zero 320000\n",
      "ex1 division by zero 320000\n",
      "ex1 division by zero 321260\n",
      "ex1 division by zero 321260\n",
      "ex1 division by zero 322780\n",
      "ex1 division by zero 322780\n",
      "ex1 division by zero 323230\n",
      "ex1 division by zero 323230\n",
      "ex1 division by zero 331380\n",
      "ex1 division by zero 331380\n",
      "ex1 division by zero 331520\n",
      "ex1 division by zero 331520\n",
      "ex1 division by zero 332290\n",
      "ex1 division by zero 332290\n",
      "ex1 division by zero 332710\n",
      "ex1 division by zero 332710\n",
      "ex1 division by zero 333430\n",
      "ex1 division by zero 333430\n",
      "ex1 division by zero 335870\n",
      "ex1 division by zero 335870\n",
      "ex1 division by zero 335890\n",
      "ex1 division by zero 335890\n",
      "ex1 division by zero 336060\n",
      "ex1 cannot convert float NaN to integer 336060\n",
      "ex1 division by zero 339950\n",
      "ex1 division by zero 339950\n",
      "ex1 division by zero 340360\n",
      "ex1 division by zero 340360\n",
      "ex1 division by zero 340440\n",
      "ex1 division by zero 340440\n",
      "ex1 division by zero 351320\n",
      "ex1 division by zero 351320\n",
      "ex1 division by zero 353190\n",
      "ex1 division by zero 353190\n",
      "ex1 cannot convert float NaN to integer 353810\n",
      "ex1 division by zero 359090\n",
      "ex1 division by zero 359090\n",
      "ex1 division by zero 363260\n",
      "ex1 division by zero 363260\n",
      "ex1 division by zero 365590\n",
      "ex1 division by zero 365590\n",
      "ex1 division by zero 366330\n",
      "ex1 division by zero 366330\n",
      "ex1 division by zero 368770\n",
      "ex1 division by zero 368770\n",
      "ex1 division by zero 369370\n",
      "ex1 division by zero 369370\n",
      "ex1 division by zero 373200\n",
      "ex1 division by zero 373200\n",
      "ex1 division by zero 900100\n",
      "ex1 division by zero 900100\n",
      "ex1 division by zero 900110\n",
      "ex1 division by zero 900110\n",
      "ex1 division by zero 900290\n",
      "ex1 division by zero 900290\n",
      "ex1 division by zero 950160\n",
      "ex1 division by zero 950160\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "import datetime\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "ADDR = '192.168.56.100'\n",
    "PORT = '3306'\n",
    "DB = 'INDEX_DUCK'\n",
    "ID = 'root'\n",
    "PW = 'root'\n",
    "# PW = 'test'\n",
    "\n",
    "db = pymysql.connect(host=ADDR, port=int(PORT), user=ID, passwd=PW, db=DB, charset='utf8')\n",
    "cursor = db.cursor()\n",
    "\n",
    "n_days = [10, 14]\n",
    "\n",
    "start = '20190101'\n",
    "end = '20211025'\n",
    "\n",
    "try:\n",
    "  getTickersSql = \"SELECT DISTINCT ticker FROM stocks_price\"\n",
    "  cursor.execute(getTickersSql)\n",
    "  tickers = list(cursor.fetchall())\n",
    "\n",
    "  for ticker in tickers:\n",
    "    for day in n_days:\n",
    "      try:\n",
    "        # Get ticker's price\n",
    "        cursor.execute(\"SELECT * FROM stocks_price WHERE ticker = '\" + ticker[0] + \"' AND date >= '\"+ start +\"' AND date <= '\"+ end + \"' ORDER BY date DESC\")\n",
    "        priceDf = pd.DataFrame(cursor.fetchall())\n",
    "        priceDf = priceDf.rename(columns={0: 'date', 1:'ticker', 2:'open', 3:'high', 4:'low', 5:'close', 6:'volume'})\n",
    "        priceDf['period'] = day\n",
    "        priceDf['tp'] = 0\n",
    "        priceDf['mfi'] = 0\n",
    "        priceDf['mfi_diff'] = 0\n",
    "        # Set typical price\n",
    "        for idx in range(0, len(priceDf)):\n",
    "          row = priceDf.iloc[idx]\n",
    "          priceDf.at[idx, 'tp'] = round((row['high'] + row['low'] + row['close']) / 3)\n",
    "        # Set MFI\n",
    "        for idx in range(0, len(priceDf)):\n",
    "          if idx + day > len(priceDf) - 1:\n",
    "            continue\n",
    "          positiveRMF = 0\n",
    "          negativeRMF = 0          \n",
    "          for i in range(idx, idx + day):\n",
    "            today = priceDf.iloc[i]\n",
    "            yesterday = priceDf.iloc[i + 1]\n",
    "            if today['tp'] > yesterday['tp']:\n",
    "              positiveRMF += today['tp'] * today['volume']\n",
    "            elif today['tp'] < yesterday['tp']:\n",
    "              negativeRMF += today['tp'] * today['volume']\n",
    "          MFI = round(positiveRMF / (positiveRMF + negativeRMF) * 100)\n",
    "          priceDf.at[idx, 'mfi'] = MFI\n",
    "          if idx > 0:\n",
    "            priceDf.at[idx - 1, 'mfi_diff'] = priceDf.iloc[idx - 1]['mfi'] - MFI\n",
    "        mfiDf = priceDf.reset_index().set_index('date').drop(['index', 'open', 'high', 'low', 'close', 'volume'], axis=1)\n",
    "        db_connection = create_engine('mysql+pymysql://'+ ID +':'+ PW +'@'+ ADDR +':'+ PORT +'/'+ DB, encoding='utf-8')\n",
    "        conn = db_connection.connect()\n",
    "        mfiDf.to_sql(name='mfi', con=db_connection, if_exists='append', index=True, index_label=\"date\")        \n",
    "        conn.close()\n",
    "      except Exception as ex1:\n",
    "        print('ex1', ex1, ticker[0])\n",
    "        pass\n",
    "except Exception as ex2:\n",
    "  print('ex2', ex2)\n",
    "  pass\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bollinger squeeze back test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ex1 \"None of ['date'] are in the columns\" 000040\n",
      "ex1 \"None of ['date'] are in the columns\" 000150\n",
      "ex1 \"None of ['date'] are in the columns\" 000155\n",
      "ex1 \"None of ['date'] are in the columns\" 000157\n",
      "ex1 \"None of ['date'] are in the columns\" 000210\n",
      "ex1 \"None of ['date'] are in the columns\" 000215\n",
      "ex1 \"None of ['date'] are in the columns\" 001020\n",
      "ex1 \"None of ['date'] are in the columns\" 001210\n",
      "ex1 \"None of ['date'] are in the columns\" 001770\n",
      "ex1 \"None of ['date'] are in the columns\" 002070\n",
      "ex1 \"None of ['date'] are in the columns\" 002380\n",
      "ex1 \"None of ['date'] are in the columns\" 002420\n",
      "ex1 \"None of ['date'] are in the columns\" 002630\n",
      "ex1 \"None of ['date'] are in the columns\" 002840\n",
      "ex1 \"None of ['date'] are in the columns\" 003280\n",
      "ex1 \"None of ['date'] are in the columns\" 003410\n",
      "ex1 \"None of ['date'] are in the columns\" 003550\n",
      "ex1 \"None of ['date'] are in the columns\" 003555\n",
      "ex1 \"None of ['date'] are in the columns\" 003620\n",
      "ex1 \"None of ['date'] are in the columns\" 004150\n",
      "ex1 \"None of ['date'] are in the columns\" 004540\n",
      "ex1 \"None of ['date'] are in the columns\" 004545\n",
      "ex1 \"None of ['date'] are in the columns\" 004920\n",
      "ex1 \"None of ['date'] are in the columns\" 005420\n",
      "ex1 \"None of ['date'] are in the columns\" 005850\n",
      "ex1 \"None of ['date'] are in the columns\" 006980\n",
      "ex1 \"None of ['date'] are in the columns\" 007120\n",
      "ex1 \"None of ['date'] are in the columns\" 007630\n",
      "ex1 \"None of ['date'] are in the columns\" 007700\n",
      "ex1 \"None of ['date'] are in the columns\" 008060\n",
      "ex1 \"None of ['date'] are in the columns\" 00806K\n",
      "ex1 \"None of ['date'] are in the columns\" 009410\n",
      "ex1 \"None of ['date'] are in the columns\" 009415\n",
      "ex1 \"None of ['date'] are in the columns\" 009810\n",
      "ex1 \"None of ['date'] are in the columns\" 010140\n",
      "ex1 \"None of ['date'] are in the columns\" 010145\n",
      "ex1 \"None of ['date'] are in the columns\" 010580\n",
      "ex1 \"None of ['date'] are in the columns\" 010660\n",
      "ex1 \"None of ['date'] are in the columns\" 011300\n",
      "ex1 \"None of ['date'] are in the columns\" 011690\n",
      "ex1 \"None of ['date'] are in the columns\" 011790\n",
      "ex1 \"None of ['date'] are in the columns\" 012170\n",
      "ex1 \"None of ['date'] are in the columns\" 012600\n",
      "ex1 \"None of ['date'] are in the columns\" 013000\n",
      "ex1 \"None of ['date'] are in the columns\" 013520\n",
      "ex1 \"None of ['date'] are in the columns\" 015230\n",
      "ex1 \"None of ['date'] are in the columns\" 015260\n",
      "ex1 \"None of ['date'] are in the columns\" 015540\n",
      "ex1 \"None of ['date'] are in the columns\" 016380\n",
      "ex1 \"None of ['date'] are in the columns\" 016385\n",
      "ex1 \"None of ['date'] are in the columns\" 020560\n",
      "ex1 \"None of ['date'] are in the columns\" 021820\n",
      "ex1 \"None of ['date'] are in the columns\" 023450\n",
      "ex1 \"None of ['date'] are in the columns\" 025560\n",
      "ex1 \"None of ['date'] are in the columns\" 030790\n",
      "ex1 \"None of ['date'] are in the columns\" 032350\n",
      "ex1 \"None of ['date'] are in the columns\" 036420\n",
      "ex1 \"None of ['date'] are in the columns\" 042670\n",
      "ex1 \"None of ['date'] are in the columns\" 044380\n",
      "ex1 \"None of ['date'] are in the columns\" 069460\n",
      "ex1 \"None of ['date'] are in the columns\" 089590\n",
      "ex1 \"['ticker' 'period' 'bandWidth'] not found in axis\" 089860\n",
      "ex1 \"None of ['date'] are in the columns\" 095720\n",
      "ex1 \"None of ['date'] are in the columns\" 097230\n",
      "ex1 \"None of ['date'] are in the columns\" 109070\n",
      "ex1 \"None of ['date'] are in the columns\" 130660\n",
      "ex1 \"['ticker' 'period' 'bandWidth'] not found in axis\" 137310\n",
      "ex1 \"['ticker' 'period' 'bandWidth'] not found in axis\" 139990\n",
      "ex1 \"None of ['date'] are in the columns\" 144620\n",
      "ex1 \"None of ['date'] are in the columns\" 145210\n",
      "ex1 \"['ticker' 'period' 'bandWidth'] not found in axis\" 248070\n",
      "ex1 \"['ticker' 'period' 'bandWidth'] not found in axis\" 259960\n",
      "ex1 \"None of ['date'] are in the columns\" 267850\n",
      "ex1 \"['ticker' 'period' 'bandWidth'] not found in axis\" 271940\n",
      "ex1 \"None of ['date'] are in the columns\" 298690\n",
      "ex1 \"['ticker' 'period' 'bandWidth'] not found in axis\" 302440\n",
      "ex1 \"['ticker' 'period' 'bandWidth'] not found in axis\" 323410\n",
      "ex1 \"None of ['date'] are in the columns\" 329180\n",
      "ex1 \"['ticker' 'period' 'bandWidth'] not found in axis\" 361610\n",
      "ex1 \"['ticker' 'period' 'bandWidth'] not found in axis\" 372910\n",
      "ex1 \"['ticker' 'period' 'bandWidth'] not found in axis\" 375500\n",
      "ex1 \"['ticker' 'period' 'bandWidth'] not found in axis\" 37550K\n",
      "ex1 \"['ticker' 'period' 'bandWidth'] not found in axis\" 378850\n",
      "ex1 \"['ticker' 'period' 'bandWidth'] not found in axis\" 380440\n",
      "ex1 \"['ticker' 'period' 'bandWidth'] not found in axis\" 383220\n",
      "ex1 \"['ticker' 'period' 'bandWidth'] not found in axis\" 383800\n",
      "ex1 \"['ticker' 'period' 'bandWidth'] not found in axis\" 38380K\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "import datetime\n",
    "import traceback\n",
    "import itertools\n",
    "\n",
    "ADDR = '192.168.56.100'\n",
    "PORT = '3306'\n",
    "DB = 'INDEX_DUCK'\n",
    "ID = 'root'\n",
    "PW = 'root'\n",
    "# PW = 'test'\n",
    "\n",
    "db = pymysql.connect(host=ADDR, port=int(PORT), user=ID, passwd=PW, db=DB, charset='utf8')\n",
    "cursor = db.cursor()\n",
    "\n",
    "### Back test 파라미터\n",
    "## 기간\n",
    "start = \"20210101\"\n",
    "end = \"20211001\"\n",
    "## 투자금\n",
    "amount = 1000000\n",
    "\n",
    "param_grid = {\n",
    "              'market': ['KOSPI'],\n",
    "              'position_bid': [0.6],\n",
    "              'position_ask': [0.3],\n",
    "              'mfi_bid': [75],\n",
    "              'mfi_ask': [10],\n",
    "              'z_score': [-1.2],\n",
    "              'maxPnl': [20],\n",
    "              'z_score_period': [180],\n",
    "              'mfi_period': [10]\n",
    "              }\n",
    "# generate all combinations of parameters\n",
    "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "\n",
    "pnlHistory = []\n",
    "\n",
    "for params in all_params:\n",
    "  market = params['market']\n",
    "  position_bid = params['position_bid']\n",
    "  position_ask = params['position_ask']\n",
    "  mfi_bid = params['mfi_bid']\n",
    "  mfi_ask = params['mfi_ask']\n",
    "  z_score = params['z_score']\n",
    "  maxPnl = params['maxPnl']\n",
    "  z_score_period = params['z_score_period']\n",
    "  mfi_period = params['mfi_period']\n",
    "\n",
    "  try:\n",
    "    if market != 'ALL':\n",
    "      cursor.execute(\"SELECT DISTINCT ticker FROM stocks_info WHERE market='\" + market + \"'\")\n",
    "    else:\n",
    "      cursor.execute(\"SELECT DISTINCT ticker FROM stocks_info\")\n",
    "    tickers = list(cursor.fetchall())\n",
    "\n",
    "    totalHistory = []\n",
    "    orderHistory = []\n",
    "    totalPNL = 0\n",
    "    winCnt, loseCnt, winRate = 0, 0, 0\n",
    "    for ticker in tickers:\n",
    "      try:\n",
    "        # Get bollinger band dataframe\n",
    "        cursor.execute(\"SELECT * FROM boll WHERE ticker = '\" + ticker[0] + \"' AND date >= '\"+ start +\"' AND date <= '\"+ end + \"' ORDER BY date\")\n",
    "        bollDf = pd.DataFrame(cursor.fetchall()).rename(columns={0:'date', 1:'ticker', 2:'close', 3:'low', 4:'medium', 5:'high', 6:'bandWidth', 7:'position'})\n",
    "        bollDf.set_index('date', drop=True, inplace=True)\n",
    "        # Get MFI dataframe\n",
    "        cursor.execute(\"SELECT * FROM mfi WHERE ticker = '\" + ticker[0] + \"' AND date >= '\"+ start +\"' AND date <= '\"+ end + \"' AND period = '\" + str(mfi_period) + \"' ORDER BY date\")\n",
    "        mfiDf = pd.DataFrame(cursor.fetchall()).rename(columns={0:'date', 1:'ticker', 2:'period', 3:'tp', 4:'mfi'})      \n",
    "        mfiDf.set_index('date', drop=True, inplace=True)\n",
    "        mfiDf = mfiDf.drop(['ticker', 'period'], axis=1)\n",
    "        # Get z-score dataframe\n",
    "        cursor.execute(\"SELECT * FROM z_score WHERE ticker = '\" + ticker[0] + \"' AND date >= '\"+ start +\"' AND date <= '\"+ end + \"' AND period = '\" + str(z_score_period) + \"' ORDER BY date\")\n",
    "        zscoreDf = pd.DataFrame(cursor.fetchall()).rename(columns={0:'date', 1:'ticker', 2:'period', 3:'bandWidth', 4:'z_score'})      \n",
    "        zscoreDf = zscoreDf.drop(['ticker', 'period', 'bandWidth'], axis=1)\n",
    "        zscoreDf.set_index('date', drop=True, inplace=True)\n",
    "        sumDf = pd.concat([bollDf, mfiDf, zscoreDf], axis=1)\n",
    "\n",
    "        isBid = False\n",
    "        bidPrice = 0\n",
    "        bidDate = '000000'      \n",
    "        for idx in sumDf.index:\n",
    "          row = sumDf.loc[idx].copy()\n",
    "          if pd.isna(row['z_score']):\n",
    "            continue\n",
    "          # Bid Step\n",
    "          if not isBid:\n",
    "            if row['position'] >= position_bid and row['mfi'] >= mfi_bid and row['z_score'] < z_score:\n",
    "              row['status'] = 'bid'\n",
    "              bidPrice = row['close']\n",
    "              bidDate = row.name.strftime(\"%Y%m%d\")\n",
    "              totalHistory.append(row)\n",
    "              orderHistory.append(['bid', ticker[0], bidDate, bidPrice])\n",
    "              isBid = True\n",
    "          # Ask Step\n",
    "          else:\n",
    "            askPrice = row['close']\n",
    "            askDate = row.name.strftime(\"%Y%m%d\")\n",
    "            pnl = (1 - (bidPrice / askPrice)) * 100\n",
    "            if row['position'] <= position_ask or row['mfi'] <= mfi_ask or pnl > maxPnl:\n",
    "              row['status'] = 'ask'\n",
    "              totalHistory.append(row)\n",
    "              orderHistory.append(['ask', ticker[0], askDate, askPrice])\n",
    "              isBid = False\n",
    "              if pnl > 0:\n",
    "                winCnt += 1\n",
    "              else:\n",
    "                loseCnt += 1\n",
    "              if not pd.isna(pnl):\n",
    "                totalPNL += pnl\n",
    "      except Exception as ex1:\n",
    "        # print('ex1', traceback.format_exc(), ex1, ticker[0])\n",
    "        print('ex1',  ex1, ticker[0])\n",
    "        pass\n",
    "    winRate = (winCnt / (winCnt + loseCnt)) * 100\n",
    "    pnlHistory.append([params, winRate, totalPNL, totalHistory, orderHistory])    \n",
    "  except Exception as ex2:\n",
    "    print('ex2', ex2)\n",
    "    pass\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'market': 'KOSPI', 'position_bid': 0.6, 'position_ask': 0.3, 'mfi_bid': 75, 'mfi_ask': 10, 'z_score': -1.2, 'maxPnl': 20, 'z_score_period': 180, 'mfi_period': 10} 41.55844155844156 684.6652375964878\n"
     ]
    }
   ],
   "source": [
    "# pnlHistory.sort(key= lambda x: [-x[2], -x[1]])\n",
    "for idx, history in enumerate(pnlHistory):\n",
    "  print(history[0], history[1], history[2])\n",
    "  # print(markets[idx], history[0], history[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20210426 59\n"
     ]
    }
   ],
   "source": [
    "orders = pnlHistory[0][4]\n",
    "orders.sort(key = lambda x : x[2])\n",
    "# orders\n",
    "cnt = 0\n",
    "maxCnt = 0\n",
    "maxCntDate = '000000'\n",
    "for order in orders:\n",
    "  if order[0] == 'bid':\n",
    "    cnt += 1\n",
    "  else :\n",
    "    cnt -= 1\n",
    "  if cnt > maxCnt:\n",
    "    maxCnt = cnt\n",
    "    maxCntDate = order[2]\n",
    "print(maxCntDate, maxCnt)\n",
    "\n",
    "# for order  in orders:\n",
    "  # print(order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bollinger Backtest (date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "import datetime\n",
    "import traceback\n",
    "import itertools\n",
    "\n",
    "ADDR = '192.168.56.100'\n",
    "PORT = '3306'\n",
    "DB = 'INDEX_DUCK'\n",
    "ID = 'root'\n",
    "PW = 'root'\n",
    "# PW = 'test'\n",
    "\n",
    "db = pymysql.connect(host=ADDR, port=int(PORT), user=ID, passwd=PW, db=DB, charset='utf8')\n",
    "cursor = db.cursor()\n",
    "\n",
    "### Back test 파라미터\n",
    "## 기간\n",
    "start = \"20210701\"\n",
    "end = \"20211108\"\n",
    "## 투자금\n",
    "totalAmount = 10000000\n",
    "step = 10\n",
    "tradeAmount = totalAmount / step\n",
    "\n",
    "param_grid = {\n",
    "              'market': ['KOSPI'],\n",
    "              'position_bid': [0.1],\n",
    "              'position_ask': [0.8],\n",
    "              'mfi_bid': [10],\n",
    "              'mfi_ask': [90],\n",
    "              'boll_period': [20],\n",
    "              'mfi_period': [10],\n",
    "              'minCap': [1000000000000],\n",
    "              # 'z_score': [-1.5],\n",
    "              # 'maxPnl': [10],\n",
    "              # 'lossCutPnl': [-20],\n",
    "              # 'z_score_period': [180]\n",
    "              }\n",
    "# generate all combinations of parameters\n",
    "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "\n",
    "tradeHistorys = []\n",
    "\n",
    "for params in all_params:\n",
    "  market = params['market']\n",
    "  position_bid = params['position_bid']\n",
    "  position_ask = params['position_ask']\n",
    "  mfi_bid = params['mfi_bid']\n",
    "  mfi_ask = params['mfi_ask']\n",
    "  boll_period = params['boll_period']\n",
    "  mfi_period = params['mfi_period']\n",
    "  minCap = params['minCap']\n",
    "  # lossCutPnl = params['lossCutPnl']\n",
    "\n",
    "  try:\n",
    "    # Ticker, Period init\n",
    "    getPeriodSql = \"SELECT DISTINCT date FROM stocks_price WHERE date >= \"+ start +\" AND date <= \"+ end +\" ORDER BY date\"\n",
    "    cursor.execute(getPeriodSql)\n",
    "    periods = list(map(lambda p: p[0].strftime(\"%Y%m%d\"), cursor.fetchall()))\n",
    "\n",
    "    bidBasket = {}\n",
    "    tradeHistory = []\n",
    "\n",
    "    for date in periods:\n",
    "      try:\n",
    "        sql = \"\"\"\n",
    "        SELECT BOLMFI.*, INFO.name, INFO.market, INFO.cap\n",
    "        FROM (\n",
    "          SELECT BOL.*, MFI.tp, MFI.mfi, MFI.mfi_diff\n",
    "          FROM (\n",
    "            SELECT * \n",
    "            FROM boll \n",
    "            WHERE date = %s\n",
    "            AND period = %s\n",
    "          ) AS BOL\n",
    "          JOIN (\n",
    "            SELECT ticker, tp, mfi, mfi_diff\n",
    "            FROM mfi\n",
    "            WHERE date = %s\n",
    "            AND period = %s\n",
    "          ) AS MFI\n",
    "          ON (BOL.ticker = MFI.ticker)\n",
    "        ) AS BOLMFI\n",
    "        JOIN (\n",
    "          SELECT ticker, name, market, cap\n",
    "          FROM stocks_info\n",
    "          WHERE cap > %s\n",
    "          AND market = '%s'\n",
    "        ) AS INFO\n",
    "        ON (BOLMFI.ticker = INFO.ticker)\n",
    "        ORDER BY INFO.cap DESC\n",
    "        \"\"\" % (date, boll_period, date, mfi_period, minCap, market)\n",
    "        # \"\"\" % (date, boll_period, date, mfi_period, minCap, market)\n",
    "        cursor.execute(sql)\n",
    "        sumDf = pd.DataFrame(cursor.fetchall()).rename(columns={0:'date', 1:'ticker', 2:'period', 3:'close', 4:'low', 5:'medium', 6:'high', 7:'bandWidth', 8:'position', 9: 'tp', 10: 'mfi', 11: 'mfi_diff', 12: 'name', 13: 'market', 14:'cap'})\n",
    "        sumDf.set_index('ticker', drop=True, inplace=True)\n",
    "\n",
    "        for idx in sumDf.index:\n",
    "          row = sumDf.loc[idx].copy()\n",
    "          ticker = row.name\n",
    "          ## BID\n",
    "          ### 1. Bollinger\n",
    "          if row['position'] <= position_bid and row['mfi'] <= mfi_bid and row['mfi'] > 0 and row['mfi_diff'] > 0:\n",
    "          ### 2. 급등주 잡기\n",
    "          # if row['position'] >= position_bid and row['mfi'] >= mfi_bid and row['z_score'] < z_score:       \n",
    "          # if row['position'] >= 0.8 and row['mfi'] >= 85 and row['mfi'] - row['mfi_diff']  < 85:\n",
    "            # 이미 매수한 종목 확인\n",
    "            if ticker in bidBasket:\n",
    "              continue\n",
    "            # 매수\n",
    "            elif ticker not in bidBasket and len(bidBasket) < step:\n",
    "              bidBasket[ticker] = [row['date'], ticker, row['close']]\n",
    "              tradeHistory.append(['bid', row['date'], ticker, row['close'], row['position'], row['mfi'], row['cap']])\n",
    "          if ticker in bidBasket:\n",
    "            bidPrice = bidBasket[ticker][2]\n",
    "            pnl = (1 - (bidPrice / row['close'])) * 100\n",
    "            ## ASK\n",
    "            ### 1. Bollinger\n",
    "            if row['position'] >= position_ask or row['mfi'] >= mfi_ask:            # 매수종목여부 확인\n",
    "            # if row['position'] >= position_ask or row['mfi'] >= mfi_ask or pnl < lossCutPnl:            # 매수종목여부 확인\n",
    "            ### 2. 급등주 잡기\n",
    "            # if row['position'] <= position_ask or row['mfi'] <= mfi_ask or pnl > maxPnl:\n",
    "            # if row['position'] <= 0.2 or row['mfi'] <= 20 or pnl > 5 :\n",
    "              del(bidBasket[ticker])\n",
    "              tradeHistory.append(['ask', row['date'], ticker, row['close'], row['position'], row['mfi'], row['cap'], pnl, tradeAmount * pnl * 0.01])\n",
    "      except Exception as ex1:\n",
    "        print('ex1', traceback.format_exc(), ex1)\n",
    "        # print('ex1', traceback.format_exc(), ex1, ticker[0])\n",
    "    tradeHistorys.append([params, tradeHistory])\n",
    "  except Exception as ex2:\n",
    "    print('ex2', ex2)\n",
    "    pass\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'market': 'KOSPI', 'position_bid': 0.1, 'position_ask': 0.8, 'mfi_bid': 10, 'mfi_ask': 90, 'boll_period': 20, 'mfi_period': 10, 'minCap': 1000000000000}, 606062.3287122858, 0.7692307692307693, 10]\n"
     ]
    }
   ],
   "source": [
    "answer = []\n",
    "\n",
    "for params, tradeHistory in tradeHistorys:\n",
    "  amt = 0\n",
    "  pnl = 0\n",
    "  w, l = 0, 0\n",
    "  for trade in tradeHistory:\n",
    "    if trade[0] == 'ask':\n",
    "      pnl += trade[7]\n",
    "      amt += trade[8]\n",
    "      if trade[7] > 0:\n",
    "        w += 1\n",
    "      else:\n",
    "        l += 1\n",
    "  tmp = tradeHistory\n",
    "  tmp.sort(key = lambda x: x[1])\n",
    "\n",
    "  cnt = 0\n",
    "  maxCnt = 0\n",
    "  for t in tmp:\n",
    "    if t[0] == 'bid':\n",
    "      cnt += 1\n",
    "    else:\n",
    "      cnt -= 1\n",
    "    if cnt > maxCnt:\n",
    "      maxCnt = cnt\n",
    "\n",
    "  if w + l != 0:\n",
    "    answer.append([params, amt, w / (w+l), maxCnt])\n",
    "    # print(params)\n",
    "    # print(pnl, amt, w / (w + l))\n",
    "\n",
    "answer.sort(key=lambda x: [-x[1], -x[2]])\n",
    "for trade in answer:\n",
    "  print(trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bid', datetime.date(2021, 7, 30), '192820', 124000, 0.04672062224090814, 8.377117311417539, 1373290589000]\n",
      "['bid', datetime.date(2021, 8, 3), '000150', 93000, 0.07186147186147186, 6.915673993119845, 1536716655000]\n",
      "['bid', datetime.date(2021, 8, 11), '004000', 69200, 0.08898643256185156, 8.888771285827533, 2334900000000]\n",
      "['ask', datetime.date(2021, 8, 12), '192820', 135000, 0.8387081385363993, 75.37854724724706, 1373290589000, 8.148148148148149, 81481.48148148149]\n",
      "['bid', datetime.date(2021, 8, 17), '298020', 775000, -0.03915424647829759, 9.705010201181995, 2722111978000]\n",
      "['bid', datetime.date(2021, 8, 18), '009540', 116500, 0.04109529595556327, 6.693871155320129, 6864992252000]\n",
      "['bid', datetime.date(2021, 8, 18), '006650', 224000, 0.038586842813163165, 9.798239405517881, 1394250000000]\n",
      "['bid', datetime.date(2021, 8, 18), '001800', 15850, 0.015590200445434299, 9.162996997423448, 1011723565300]\n",
      "['bid', datetime.date(2021, 8, 19), '002380', 293500, -0.056705755918702784, 8.626550388995877, 3550145164500]\n",
      "['bid', datetime.date(2021, 8, 23), '028260', 129000, 0.09402828706128863, 4.86322248495473, 22706780341500]\n",
      "['bid', datetime.date(2021, 8, 23), '018260', 169000, 0.07525613621286946, 6.616985614143927, 12225692400000]\n",
      "['bid', datetime.date(2021, 8, 23), '078930', 40000, 0.04567354018115244, 8.425861644349313, 4106859707600]\n",
      "['ask', datetime.date(2021, 8, 25), '002380', 363000, 0.9117552074923301, 72.11771248376947, 3550145164500, 19.146005509641874, 191460.05509641874]\n",
      "['ask', datetime.date(2021, 9, 1), '000150', 100000, 0.9493247143022048, 56.555943970770485, 1536716655000, 6.999999999999995, 69999.99999999994]\n",
      "['ask', datetime.date(2021, 9, 6), '004000', 71900, 0.8650963597430407, 83.6415197363534, 2334900000000, 3.7552155771905404, 37552.1557719054]\n",
      "['ask', datetime.date(2021, 9, 8), '078930', 43100, 0.9091162531363256, 61.351134995685754, 4106859707600, 7.1925754060324865, 71925.75406032486]\n",
      "['ask', datetime.date(2021, 9, 13), '006650', 238500, 0.879156134551818, 57.10799660324901, 1394250000000, 6.079664570230603, 60796.645702306036]\n",
      "['ask', datetime.date(2021, 9, 13), '001800', 16300, 0.855072463768116, 55.53553564067695, 1011723565300, 2.7607361963190136, 27607.361963190135]\n",
      "['bid', datetime.date(2021, 9, 23), '185750', 122500, 0.08238586671331118, 9.333295427855571, 1428262375000]\n",
      "['bid', datetime.date(2021, 9, 24), '000990', 56700, 0.05708661417322835, 7.952653332325703, 2362004881600]\n",
      "['bid', datetime.date(2021, 9, 27), '002790', 50400, 0.06631081913364813, 7.477222369103011, 3949746822000]\n",
      "['bid', datetime.date(2021, 9, 28), '012330', 253000, -0.07848243127430944, 9.09543082284907, 23650876953000]\n",
      "['bid', datetime.date(2021, 9, 28), '008560', 5030, 0.0339943342776204, 4.38345738304861, 3371157713155]\n",
      "['bid', datetime.date(2021, 9, 28), '011210', 79100, 0.018220928761229913, 9.257756243896653, 1996119092200]\n",
      "['ask', datetime.date(2021, 10, 13), '011210', 89700, 0.9178575511603978, 67.16932740331131, 1996119092200, 11.817168338907468, 118171.68338907468]\n",
      "['ask', datetime.date(2021, 10, 14), '012330', 273000, 0.8662914806908597, 62.79840091409613, 23650876953000, 7.326007326007322, 73260.07326007323]\n",
      "['ask', datetime.date(2021, 10, 20), '002790', 52500, 0.8223022662464355, 76.04947482315183, 3949746822000, 4.0000000000000036, 40000.00000000004]\n",
      "['ask', datetime.date(2021, 10, 25), '009540', 101500, 0.8187776642832822, 65.65893910337412, 6864992252000, -14.778325123152714, -147783.25123152716]\n",
      "['ask', datetime.date(2021, 10, 25), '000990', 55900, 0.837181764357608, 76.07933549064447, 2362004881600, -1.4311270125223707, -14311.270125223708]\n",
      "['bid', datetime.date(2021, 11, 1), '018880', 14500, 0.06324110671936758, 9.449878847635752, 8060380000000]\n",
      "['bid', datetime.date(2021, 11, 1), '002380', 327000, 0.03946271642573055, 7.238001608697109, 3550145164500]\n",
      "['bid', datetime.date(2021, 11, 1), '006650', 184000, -0.013036513285090869, 6.225837895400596, 1394250000000]\n",
      "['ask', datetime.date(2021, 11, 2), '185750', 122000, 0.8619417108251325, 67.49640478231723, 1428262375000, -0.4098360655737654, -4098.360655737653]\n",
      "['bid', datetime.date(2021, 11, 4), '004800', 99700, 0.03407968389858413, 6.87839353410656, 2370490312500]\n",
      "['bid', datetime.date(2021, 11, 5), '086280', 163500, 0.06509246682687285, 7.293422513970651, 6056250000000]\n"
     ]
    }
   ],
   "source": [
    "for trade in sorted(tradeHistorys[0][1], key = lambda x: [x[1]]):\n",
    "# for trade in tradeHistory:\n",
    "  print(trade)\n",
    "\n",
    "# for trade in tradeHistory:\n",
    "#   if trade[0] == 'ask' and trade[7] < 0:\n",
    "#     print(trade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 최적해 찾기\n",
    "## 고정\n",
    "start = \"20200101\"\n",
    "end = \"20211001\"\n",
    "\n",
    "## z_score\n",
    "- 고정\n",
    "position_bid = 0.8\n",
    "position_ask = 0.2\n",
    "z_score_period = 180\n",
    "mfi_bid = 80\n",
    "mfi_ask = 20\n",
    "market = 'ALL'\n",
    "maxPnl = 100\n",
    "\n",
    "- 변인\n",
    "z_scores= [-1.0, -1.3, -1.5, -1.7, -2.0]\n",
    "\n",
    "|z_score|winRate|pnl|\n",
    "|:-:|:-:|:-:|\n",
    "|-1.0|34.32944606413994|nan|\n",
    "|-1.3|35.88850174216028|283.44426401901296|\n",
    "|-1.5|37.93103448275862|125.16153472630523|\n",
    "|-1.7|22.22222222222222|-25.09276709655087|\n",
    "|-2.0|0.0|-4.414514432628258|\n",
    "\n",
    "## position_bid\n",
    "- 고정\n",
    "position_ask = 0.2\n",
    "z_score = -1.4\n",
    "z_score_period = 180\n",
    "mfi_bid = 80\n",
    "mfi_ask = 20\n",
    "market = 'ALL'\n",
    "maxPnl = 100\n",
    "\n",
    "- 변인\n",
    "position_bids = [0.7, 0.8, 0.9]\n",
    "\n",
    "|position_bid|winRate|pnl|\n",
    "|:-:|:-:|:-:|\n",
    "|0.7|39.89637305699482|440.6378994058454|\n",
    "|0.8|39.130434782608695|315.4140939709663|\n",
    "|0.9|41.52542372881356|226.7342555923805|\n",
    "\n",
    "## position_ask\n",
    "- 고정\n",
    "position_bid = 0.7\n",
    "z_score = -1.4\n",
    "z_score_period = 180\n",
    "mfi_bid = 80\n",
    "mfi_ask = 20\n",
    "market = 'ALL'\n",
    "maxPnl = 100\n",
    "\n",
    "- 변인\n",
    "position_asks = [0.1, 0.2, 0.3]\n",
    "\n",
    "|position_ask|winRate|pnl|\n",
    "|:-:|:-:|:-:|\n",
    "|0.1|40.64171122994652|236.61480444712032|\n",
    "|0.2|39.89637305699482|440.6378994058454|\n",
    "|0.3|37.43589743589744|451.9511616901119|\n",
    "\n",
    "## mfi_bid\n",
    "- 고정\n",
    "position_bid = 0.7\n",
    "position_ask = 0.2\n",
    "z_score = -1.4\n",
    "z_score_period = 180\n",
    "mfi_ask = 20\n",
    "market = 'ALL'\n",
    "maxPnl = 100\n",
    "\n",
    "- 변인\n",
    "mfi_bids = [70, 80, 90]\n",
    "\n",
    "|mfi_bid|winRate|pnl|\n",
    "|:-:|:-:|:-:|\n",
    "|70|34.66666666666667|582.5065627636856|\n",
    "|75|36.41456582633053|640.9291524639638\n",
    "|76|35.625|501.1409719166681|\n",
    "|77|37.06293706293706|511.48579372629183|\n",
    "|78|38.82352941176471|505.1362648020545|\n",
    "|79|38.32599118942731|413.3744817126745|\n",
    "|80|39.89637305699482|440.6378994058454|\n",
    "|90|29.411764705882355|-30.240865153798886|\n",
    "\n",
    "## mfi_ask\n",
    "- 고정\n",
    "position_bid = 0.7\n",
    "position_ask = 0.2\n",
    "z_score = -1.4\n",
    "z_score_period = 180\n",
    "mfi_bid = 75\n",
    "market = 'ALL'\n",
    "maxPnl = 100\n",
    "\n",
    "- 변인\n",
    "mfi_asks = [10, 20, 30]\n",
    "\n",
    "|mfi_ask|winRate|pnl|\n",
    "|:-:|:-:|:-:|\n",
    "|10|36.33802816901409|653.5229985590347|\n",
    "|20|36.41456582633053|640.9291524639638|\n",
    "|30|36.87150837988827|621.8542290878482|\n",
    "\n",
    "## maxPnl\n",
    "- 고정\n",
    "position_bid = 0.7\n",
    "position_ask = 0.2\n",
    "z_score = -1.4\n",
    "z_score_period = 180\n",
    "mfi_bid = 75\n",
    "mfi_ask = 20\n",
    "market = 'ALL'\n",
    "\n",
    "- 변인\n",
    "maxPnls = [20, 30, 40, 100]\n",
    "\n",
    "|maxPnl|winRate|pnl|\n",
    "|:-:|:-:|:-:|\n",
    "|20|36.87150837988827|953.4103012677884|\n",
    "|25|37.19512195121951|867.1855323757495|\n",
    "|30|36.69467787114846|906.3355600527316|\n",
    "|40|36.41456582633053|691.4075004426513|\n",
    "|100|36.41456582633053|640.9291524639638|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파라미터 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "param_grid = {\n",
    "              'market': ['KOSPI', 'KOSDAQ'],\n",
    "              'position_bids': [0.6, 0.7],\n",
    "              'position_asks': [0.3, 0.4],\n",
    "              'mfi_bid': [75],\n",
    "              'mfi_ask': [10],\n",
    "              'z_scores': [-1.2, -1.3, -1.4],\n",
    "              'maxPnls': [20, 30],\n",
    "              'mfi_periods': [10, 14]\n",
    "              }\n",
    "\n",
    "\n",
    "# generate all combinations of parameters\n",
    "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KOSPI'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_params[0]['market']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c968b4081f8e9392c017ceade3e01ae64d66c3f9c92847f587ebc7e83dc00868"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 32-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
